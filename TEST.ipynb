{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb4b384f-d8c1-4a7f-8560-5f3a99f8a60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from gensim.utils import tokenize\n",
    "from tqdm import tqdm\n",
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "from torch.optim import AdamW\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "data=load_dataset('imdb')\n",
    "device='cpu'\n",
    "from torch.nn import Module\n",
    "from torch import nn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46a17466-6e1d-4801-a521-4d4bcf73d7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 25000/25000 [00:24<00:00, 1019.94it/s]\n"
     ]
    }
   ],
   "source": [
    "all_sentences=[]\n",
    "sent_threshold=32\n",
    "\n",
    "for text_block in tqdm(data['train']['text']):\n",
    "    for sentences in TextBlob(text_block).sentences:\n",
    "        len_of_sent=sentences.words \n",
    "        for sent in sentences.split('.<br /><br />'):\n",
    "            if len(len_of_sent)<sent_threshold:\n",
    "                all_sentences.append(sent)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "161c85e5-4ba3-4474-b0c6-e2ff368bd35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 227434/227434 [00:01<00:00, 125180.27it/s]\n"
     ]
    }
   ],
   "source": [
    "words=[]\n",
    "for sent in tqdm(all_sentences):\n",
    "    for word in tokenize(sent):\n",
    "        words.append(word.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "153a013e-f901-4805-9a6d-dd8e74dcd14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cntr=Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb0b2108-594f-4c1c-be86-c22363276fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=40000\n",
    "our_words=set(['<unk>','<bos>','<eos>','<pad>'])\n",
    "for word,cnt in cntr.most_common()[0:vocab_size]:\n",
    "    our_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "455d81c4-3a06-4cd2-a3d0-63dbdb660c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40004"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(our_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66f4460d-4d65-4269-9b9a-ede65b5e0e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "Am\n",
      "Curious\n",
      "Yellow\n",
      "is\n",
      "a\n",
      "risible\n",
      "and\n",
      "pretentious\n",
      "steaming\n",
      "pile\n"
     ]
    }
   ],
   "source": [
    "for i in tokenize(all_sentences[5]):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ba803f6-e3d5-466a-a755-9b9bba2bb0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2int={word:cnt for cnt,word in enumerate(our_words)}\n",
    "int2word={cnt:word for cnt,word in enumerate(our_words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50f8c7bf-6735-41eb-8264-e6f0cc1ef9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class word_dataset(Dataset):\n",
    "    def __init__(self,data):\n",
    "        super(word_dataset,self).__init__()\n",
    "        self.data=data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        selected_sent=self.data[idx]\n",
    "        indexed_text=[word2int['<bos>']]\n",
    "        main_text=[word2int[word] if word in word2int else word2int['<unk>'] for word in tokenize(selected_sent.lower())]\n",
    "        indexed_text=indexed_text+main_text+[word2int['<eos>']]\n",
    "        return indexed_text\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d264972-1229-42f5-9c59-c9b0f1ad0e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(batch):\n",
    "    lenghts=(len(x) for x in batch)\n",
    "    max_len=max(lenghts)\n",
    "\n",
    "    new_batch=[]\n",
    "    for sent in batch:\n",
    "        for pad in range(max_len-len(sent)):\n",
    "            sent.append(word2int['<pad>'])\n",
    "        new_batch.append(sent)\n",
    "\n",
    "    new_batch=torch.LongTensor(new_batch).to(device)\n",
    "\n",
    "    \n",
    "\n",
    "    return {\n",
    "        'inp':new_batch[:,:-1],\n",
    "        'label':new_batch[:,1:]\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afe11823-45b8-4842-b796-85419a4f09cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=word_dataset(all_sentences)\n",
    "train_dataloader=DataLoader(train_data,batch_size=32,shuffle=True,collate_fn=make_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a56789a9-6de8-4780-81b5-8d2c5ea958df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel(Module):\n",
    "    def __init__(self,vocab_size,hidden_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.emb=nn.Embedding(vocab_size,hidden_size)\n",
    "        self.gru=nn.GRU(hidden_size,hidden_size,num_layers=3,batch_first=True)\n",
    "\n",
    "        self.lay_with_drop=nn.Sequential(\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size,hidden_size),\n",
    "            nn.Dropout(),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        self.final_lin=nn.Sequential(\n",
    "            nn.Linear(hidden_size,vocab_size)\n",
    "        )\n",
    "\n",
    "        \n",
    "    def forward(self,text):\n",
    "        \n",
    "        emb_x=self.emb(text)\n",
    "        \n",
    "    \n",
    "        x,_=self.gru(emb_x)\n",
    "\n",
    "        agr_x=x.mean(dim=1)#???????\n",
    "        \n",
    "\n",
    "        x=self.lay_with_drop(agr_x)\n",
    "        x=self.final_lin(x)\n",
    "        print(x.shape)\n",
    "        return x\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2907ad28-23d9-4509-bbfe-d4da828f0e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LanguageModel(len(our_words),128)\n",
    "loss_fn=nn.CrossEntropyLoss(ignore_index=word2int['<pad>'])\n",
    "optimizer=AdamW(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a09b8c26-2b2e-4473-a395-56d248b94ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40004"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(our_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b7fbd996-535b-4932-af88-ff7e7772778b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,loss_fn,optimizer,dataloader):\n",
    "    for batch in dataloader:\n",
    "        pred=model(batch['inp']).flatten(start_dim=0,end_dim=1)\n",
    "        print(pred.shape,batch['label'].flatten().shape)\n",
    "        loss=loss_fn(pred,batch['label'].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e1edf531-1542-4deb-85d4-09c7d698d115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 40004])\n",
      "torch.Size([1280128]) torch.Size([1024])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch (got input: [1280128], target: [1024])",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, loss_fn, optimizer, dataloader)\u001b[39m\n\u001b[32m      3\u001b[39m pred=model(batch[\u001b[33m'\u001b[39m\u001b[33minp\u001b[39m\u001b[33m'\u001b[39m]).flatten(start_dim=\u001b[32m0\u001b[39m,end_dim=\u001b[32m1\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(pred.shape,batch[\u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m].flatten().shape)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m loss=\u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlabel\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/torch/nn/modules/loss.py:1295\u001b[39m, in \u001b[36mCrossEntropyLoss.forward\u001b[39m\u001b[34m(self, input, target)\u001b[39m\n\u001b[32m   1294\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) -> Tensor:\n\u001b[32m-> \u001b[39m\u001b[32m1295\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1296\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1297\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1298\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1299\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1300\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1301\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1302\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/torch/nn/functional.py:3494\u001b[39m, in \u001b[36mcross_entropy\u001b[39m\u001b[34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[39m\n\u001b[32m   3492\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3493\u001b[39m     reduction = _Reduction.legacy_get_string(size_average, reduce)\n\u001b[32m-> \u001b[39m\u001b[32m3494\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_nn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3495\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3496\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3497\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3498\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3499\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3500\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3501\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: size mismatch (got input: [1280128], target: [1024])"
     ]
    }
   ],
   "source": [
    "train(model,loss_fn,optimizer,train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c187da-5e0c-4143-9c1e-b23e141a84a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8d36f9-3c3f-4d24-9be7-ce5cbc43b68b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
