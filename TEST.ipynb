{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb4b384f-d8c1-4a7f-8560-5f3a99f8a60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from gensim.utils import tokenize\n",
    "from tqdm import tqdm\n",
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "from torch.utils.data import Dataset\n",
    "data=load_dataset('imdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46a17466-6e1d-4801-a521-4d4bcf73d7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25000/25000 [00:22<00:00, 1116.62it/s]\n"
     ]
    }
   ],
   "source": [
    "all_sentences=[]\n",
    "sent_threshold=32\n",
    "\n",
    "for text_block in tqdm(data['train']['text']):\n",
    "    for sentences in TextBlob(text_block).sentences:\n",
    "        len_of_sent=sentences.words \n",
    "        for sent in sentences.split('.<br /><br />'):\n",
    "            if len(len_of_sent)<sent_threshold:\n",
    "                all_sentences.append(sent)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "161c85e5-4ba3-4474-b0c6-e2ff368bd35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 227434/227434 [00:01<00:00, 138339.36it/s]\n"
     ]
    }
   ],
   "source": [
    "words=[]\n",
    "for sent in tqdm(all_sentences):\n",
    "    for word in tokenize(sent):\n",
    "        words.append(word.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "153a013e-f901-4805-9a6d-dd8e74dcd14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cntr=Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "eb0b2108-594f-4c1c-be86-c22363276fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=40000\n",
    "our_words=set(['<unk>','<bos>','<eos>','<pad>'])\n",
    "for word,cnt in cntr.most_common()[0:vocab_size]:\n",
    "    our_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "455d81c4-3a06-4cd2-a3d0-63dbdb660c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40004"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(our_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "66f4460d-4d65-4269-9b9a-ede65b5e0e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "Am\n",
      "Curious\n",
      "Yellow\n",
      "is\n",
      "a\n",
      "risible\n",
      "and\n",
      "pretentious\n",
      "steaming\n",
      "pile\n"
     ]
    }
   ],
   "source": [
    "for i in tokenize(all_sentences[5]):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1ba803f6-e3d5-466a-a755-9b9bba2bb0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2int={word:cnt for cnt,word in enumerate(our_words)}\n",
    "int2word={cnt:word for cnt,word in enumerate(our_words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "50f8c7bf-6735-41eb-8264-e6f0cc1ef9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class word_dataset(Dataset):\n",
    "    def __init__(self,data):\n",
    "        super(word_dataset,self).__init__()\n",
    "        self.data=data\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        selected_sent=self.data[idx]\n",
    "        indexed_text=[word2int[word] if word in word2int else word2int['<unk>'] for word in tokenize(selected_sent.lower())]\n",
    "        return indexed_text\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "afe11823-45b8-4842-b796-85419a4f09cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=word_dataset(all_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "682d80dd-7abe-43d8-ac89-a49f4845995f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[22536,\n",
       " 18879,\n",
       " 10087,\n",
       " 27778,\n",
       " 20704,\n",
       " 8592,\n",
       " 15049,\n",
       " 15518,\n",
       " 32507,\n",
       " 5075,\n",
       " 38474,\n",
       " 24477,\n",
       " 35881,\n",
       " 35625,\n",
       " 23757,\n",
       " 34969,\n",
       " 15518,\n",
       " 24944,\n",
       " 13841]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4e03eb58-f2fe-4ca6-b410-fa15ad6028fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'escapeees' in word2int:\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0491aef0-2edf-46d3-a8d5-c61bbc06313c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
